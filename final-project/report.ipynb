{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# CS152 Final Project"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Problem Definition: \n",
    "This will be an extended version of what you submitted for your proposal. It should detail the exact nature of the problem you are trying to solve, along with why this problem is interesting/significant, and why AI approaches are a good fit. [HC: #rightproblem].\n",
    "## Solution Specification: \n",
    "This section should describe your approach to solving the problem described in the problem definition section. It should detail the steps taken to solve the problem, including the AI method or methods that you have adopted, and how you applied those methods to produce your solution. [HCs: #breakitdown, #algorithms, LOs: \n",
    "will depend on those you nominated in your proposal].\n",
    "## Analysis of Solution: \n",
    "This section should present an analysis of your proposed solution operating on some relevant test cases. It should describe the test cases used, and relevant results using appropriate representations (e.g. tables and figures). [HCs: #simulation, #professionalism. LOs: will depend on those you nominated in your proposal]\n",
    "## References: \n",
    "This section should detail any references you used when formulating your problem or producing your solution.\n",
    "## Appendices: \n",
    "Include here any relevant appendices (e.g. Python or Prolog code). Also include a copy of your original proposal here."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Problem Definition\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Solution Specification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Analysis of Solution"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## References"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Appendix"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Appendix 1 Wumpus World"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Main import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running on random generated world.\n",
      "       .       .      S.       .\n",
      "\n",
      "       .     BS.      W.     GS.\n",
      "\n",
      "      B.     PB.     BS.      B.\n",
      "\n",
      "     B>.     PB.      B.      P.\n",
      "\n",
      "Score: 0\n",
      "AgentX: 0\n",
      "AgentY: 0\n",
      "AgentDir: Right\n",
      "Last Action: Climbed\n",
      "Percepts: Breeze\n",
      "       .       .      S.       .\n",
      "\n",
      "       .     BS.      W.     GS.\n",
      "\n",
      "      B.     PB.     BS.      B.\n",
      "\n",
      "     B>.     PB.      B.      P.\n",
      "\n",
      "Score: -1\n",
      "AgentX: 0\n",
      "AgentY: 0\n",
      "AgentDir: Right\n",
      "Last Action: Climbed\n",
      "Percepts: Breeze\n",
      "Your agent scored: -1\n",
      "---------------\n",
      "      B.     PB.     PB.     PB.\n",
      "\n",
      "      P.      B.      B.    PBS.\n",
      "\n",
      "      B.     PB.     BS.   PWGB.\n",
      "\n",
      "     B>.     PB.      B.     BS.\n",
      "\n",
      "Score: 0\n",
      "AgentX: 0\n",
      "AgentY: 0\n",
      "AgentDir: Right\n",
      "Last Action: Climbed\n",
      "Percepts: Breeze\n",
      "      B.     PB.     PB.     PB.\n",
      "\n",
      "      P.      B.      B.    PBS.\n",
      "\n",
      "      B.     PB.     BS.   PWGB.\n",
      "\n",
      "     B>.     PB.      B.     BS.\n",
      "\n",
      "Score: -1\n",
      "AgentX: 0\n",
      "AgentY: 0\n",
      "AgentDir: Right\n",
      "Last Action: Climbed\n",
      "Percepts: Breeze\n",
      "Your agent scored: -1\n",
      "---------------\n",
      "      B.       .       .       .\n",
      "\n",
      "      P.      B.      S.       .\n",
      "\n",
      "      B.     BS.      W.      S.\n",
      "\n",
      "     B>.      P.     BS.      G.\n",
      "\n",
      "Score: 0\n",
      "AgentX: 0\n",
      "AgentY: 0\n",
      "AgentDir: Right\n",
      "Last Action: Climbed\n",
      "Percepts: Breeze\n",
      "      B.       .       .       .\n",
      "\n",
      "      P.      B.      S.       .\n",
      "\n",
      "      B.     BS.      W.      S.\n",
      "\n",
      "     B>.      P.     BS.      G.\n",
      "\n",
      "Score: -1\n",
      "AgentX: 0\n",
      "AgentY: 0\n",
      "AgentDir: Right\n",
      "Last Action: Climbed\n",
      "Percepts: Breeze\n",
      "Your agent scored: -1\n",
      "---------------\n",
      "Invalid Input: Response must be yes or no. (y/n)\n",
      "---------------\n",
      "      S.       .       .       .\n",
      "\n",
      "      W.      S.       .       .\n",
      "\n",
      "      S.       .       .       .\n",
      "\n",
      "      >.       .       .      G.\n",
      "\n",
      "Score: 0\n",
      "AgentX: 0\n",
      "AgentY: 0\n",
      "AgentDir: Right\n",
      "Last Action: Climbed\n",
      "Percepts: \n",
      "      S.       .       .       .\n",
      "\n",
      "      W.      S.       .       .\n",
      "\n",
      "      S.       .       .       .\n",
      "\n",
      "       .      >.       .      G.\n",
      "\n",
      "Score: -1\n",
      "AgentX: 1\n",
      "AgentY: 0\n",
      "AgentDir: Right\n",
      "Last Action: Moved Forward\n",
      "Percepts: \n",
      "      S.       .       .       .\n",
      "\n",
      "      W.      S.       .       .\n",
      "\n",
      "      S.       .       .       .\n",
      "\n",
      "       .       .      >.      G.\n",
      "\n",
      "Score: -2\n",
      "AgentX: 2\n",
      "AgentY: 0\n",
      "AgentDir: Right\n",
      "Last Action: Moved Forward\n",
      "Percepts: \n",
      "      S.       .       .       .\n",
      "\n",
      "      W.      S.       .       .\n",
      "\n",
      "      S.       .       .       .\n",
      "\n",
      "       .       .       .     G>.\n",
      "\n",
      "Score: -3\n",
      "AgentX: 3\n",
      "AgentY: 0\n",
      "AgentDir: Right\n",
      "Last Action: Moved Forward\n",
      "Percepts: Glitter\n",
      "      S.       .       .       .\n",
      "\n",
      "      W.      S.       .       .\n",
      "\n",
      "      S.       .       .       .\n",
      "\n",
      "       .       .       .      >.\n",
      "\n",
      "Score: -4\n",
      "AgentX: 3\n",
      "AgentY: 0\n",
      "AgentDir: Right\n",
      "Last Action: Grabbed\n",
      "Percepts: \n",
      "      S.       .       .       .\n",
      "\n",
      "      W.      S.       .       .\n",
      "\n",
      "      S.       .       .       .\n",
      "\n",
      "       .       .       .      ^.\n",
      "\n",
      "Score: -5\n",
      "AgentX: 3\n",
      "AgentY: 0\n",
      "AgentDir: Up\n",
      "Last Action: Turned Left\n",
      "Percepts: \n",
      "      S.       .       .       .\n",
      "\n",
      "      W.      S.       .       .\n",
      "\n",
      "      S.       .       .       .\n",
      "\n",
      "       .       .       .      <.\n",
      "\n",
      "Score: -6\n",
      "AgentX: 3\n",
      "AgentY: 0\n",
      "AgentDir: Left\n",
      "Last Action: Turned Left\n",
      "Percepts: \n",
      "      S.       .       .       .\n",
      "\n",
      "      W.      S.       .       .\n",
      "\n",
      "      S.       .       .       .\n",
      "\n",
      "       .       .      <.       .\n",
      "\n",
      "Score: -7\n",
      "AgentX: 2\n",
      "AgentY: 0\n",
      "AgentDir: Left\n",
      "Last Action: Moved Forward\n",
      "Percepts: \n",
      "      S.       .       .       .\n",
      "\n",
      "      W.      S.       .       .\n",
      "\n",
      "      S.       .       .       .\n",
      "\n",
      "       .      <.       .       .\n",
      "\n",
      "Score: -8\n",
      "AgentX: 1\n",
      "AgentY: 0\n",
      "AgentDir: Left\n",
      "Last Action: Moved Forward\n",
      "Percepts: \n",
      "      S.       .       .       .\n",
      "\n",
      "      W.      S.       .       .\n",
      "\n",
      "      S.       .       .       .\n",
      "\n",
      "      <.       .       .       .\n",
      "\n",
      "Score: -9\n",
      "AgentX: 0\n",
      "AgentY: 0\n",
      "AgentDir: Left\n",
      "Last Action: Moved Forward\n",
      "Percepts: \n",
      "      S.       .       .       .\n",
      "\n",
      "      W.      S.       .       .\n",
      "\n",
      "      S.       .       .       .\n",
      "\n",
      "      <.       .       .       .\n",
      "\n",
      "Score: 990\n",
      "AgentX: 0\n",
      "AgentY: 0\n",
      "AgentDir: Left\n",
      "Last Action: Climbed\n",
      "Percepts: \n",
      "Your agent scored: 990\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ]
}